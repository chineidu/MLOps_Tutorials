{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8506e39",
   "metadata": {},
   "source": [
    "# Convert GLiNER Model To ONNX Format And Quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3764e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "from typing import Any, Literal\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# import pandas as pd\n",
    "# import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"white\": \"#FFFFFF\",  # Bright white\n",
    "        \"info\": \"#00FF00\",  # Bright green\n",
    "        \"warning\": \"#FFD700\",  # Bright gold\n",
    "        \"error\": \"#FF1493\",  # Deep pink\n",
    "        \"success\": \"#00FFFF\",  # Cyan\n",
    "        \"highlight\": \"#FF4500\",  # Orange-red\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "# pd.options.display.max_rows = 1_000\n",
    "# pd.options.display.max_columns = 1_000\n",
    "# pd.options.display.max_colwidth = 600\n",
    "\n",
    "# # Polars settings\n",
    "# pl.Config.set_fmt_str_lengths(1_000)\n",
    "# pl.Config.set_tbl_cols(n=1_000)\n",
    "# pl.Config.set_tbl_rows(n=200)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1df84732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Bike Rental Prediction', 'category': 'A'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def go_up_from_current_directory(*, go_up: int = 1) -> None:\n",
    "    \"\"\"This is used to up a number of directories.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    go_up: int, default=1\n",
    "        This indicates the number of times to go back up from the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    CONST: str = \"../\"\n",
    "    NUM: str = CONST * go_up\n",
    "\n",
    "    # Goto the previous directory\n",
    "    prev_directory = os.path.join(os.path.dirname(__name__), NUM)\n",
    "    # Get the 'absolute path' of the previous directory\n",
    "    abs_path_prev_directory = os.path.abspath(prev_directory)\n",
    "\n",
    "    # Add the path to the System paths\n",
    "    sys.path.insert(0, abs_path_prev_directory)\n",
    "    print(abs_path_prev_directory)\n",
    "\n",
    "\n",
    "# Demo (Prevents ruff from removing the unused module import)\n",
    "name: Any\n",
    "category: Literal[\"A\", \"B\", \"C\"]\n",
    "json.loads('{\"name\": \"Bike Rental Prediction\", \"category\": \"A\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c56591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d48205a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53d68f550a349b29f7b706f39835be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_small-v2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f9d065",
   "metadata": {},
   "source": [
    "## Save And Load The Model (Locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eedd23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in /Users/mac/Desktop/Projects/gliner_test/gliner_small_v_2_p_1_local\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "model.save_pretrained(\"gliner_small_v_2_p_1_local\")\n",
    "\n",
    "# load\n",
    "gliner_model = GLiNER.from_pretrained(\"gliner_small_v_2_p_1_local\", load_tokenizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db70b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "onnx_savepath: Path = Path(\"gliner_small_v_2_p_1_local\") / \"model.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b1878",
   "metadata": {},
   "source": [
    "### Prepare The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb50383",
   "metadata": {},
   "outputs": [],
   "source": [
    "text: str = (\n",
    "    \"ONNX is an open-source format designed to enable the interoperability of AI models across various frameworks and tools.\"\n",
    ")\n",
    "labels: list[str] = [\"format\", \"model\", \"tool\", \"cat\"]\n",
    "\n",
    "inputs, _ = gliner_model.prepare_model_inputs([text], labels)\n",
    "\n",
    "# Ensure text_lengths is set and is a tensor of shape (batch_size,)\n",
    "batch_size = inputs[\"input_ids\"].shape[0]\n",
    "seq_len = inputs[\"input_ids\"].shape[1]\n",
    "if \"text_lengths\" not in inputs or inputs[\"text_lengths\"] is None or not isinstance(inputs[\"text_lengths\"], torch.Tensor):\n",
    "    inputs[\"text_lengths\"] = torch.full((batch_size,), seq_len, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17750a7a",
   "metadata": {},
   "source": [
    "### Export The PyTorch Model To ONNX Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "691df4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W1108 12:19:12.538667000 shape_type_inference.cpp:1998] Warning: The shape inference of prim::PackPadded type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W1108 12:19:12.538683000 shape_type_inference.cpp:1998] Warning: The shape inference of prim::PackPadded type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W1108 12:19:12.548158000 shape_type_inference.cpp:1998] Warning: The shape inference of prim::PadPacked type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n"
     ]
    }
   ],
   "source": [
    "class GLiNERExportWrapper(torch.nn.Module):\n",
    "    def __init__(self, backend_model: torch.nn.Module, span_mode: str) -> None:\n",
    "        super().__init__()\n",
    "        self.backend_model = backend_model\n",
    "        self.span_mode = span_mode\n",
    "\n",
    "    def forward(  # type: ignore[override]\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        words_mask: torch.Tensor,\n",
    "        text_lengths: torch.Tensor,\n",
    "        span_idx: torch.Tensor | None = None,\n",
    "        span_mask: torch.Tensor | None = None,\n",
    "    ) -> torch.Tensor:\n",
    "        kwargs = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"words_mask\": words_mask,\n",
    "            \"text_lengths\": text_lengths,\n",
    "        }\n",
    "        if self.span_mode != \"token_level\":\n",
    "            kwargs[\"span_idx\"] = span_idx\n",
    "            kwargs[\"span_mask\"] = span_mask\n",
    "        return self.backend_model(**kwargs)\n",
    "\n",
    "\n",
    "export_wrapper = GLiNERExportWrapper(gliner_model.model, gliner_model.config.span_mode)\n",
    "\n",
    "if gliner_model.config.span_mode == \"token_level\":\n",
    "    all_inputs = (\n",
    "        inputs[\"input_ids\"],\n",
    "        inputs[\"attention_mask\"],\n",
    "        inputs[\"words_mask\"],\n",
    "        inputs[\"text_lengths\"],\n",
    "    )\n",
    "    input_names = [\"input_ids\", \"attention_mask\", \"words_mask\", \"text_lengths\"]\n",
    "    dynamic_axes = {\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"words_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"text_lengths\": {0: \"batch_size\", 1: \"value\"},\n",
    "        \"logits\": {\n",
    "            0: \"position\",\n",
    "            1: \"batch_size\",\n",
    "            2: \"sequence_length\",\n",
    "            3: \"num_classes\",\n",
    "        },\n",
    "    }\n",
    "else:\n",
    "    all_inputs = (\n",
    "        inputs[\"input_ids\"],\n",
    "        inputs[\"attention_mask\"],\n",
    "        inputs[\"words_mask\"],\n",
    "        inputs[\"text_lengths\"],\n",
    "        inputs[\"span_idx\"],\n",
    "        inputs[\"span_mask\"],\n",
    "    )\n",
    "    input_names = [\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"words_mask\",\n",
    "        \"text_lengths\",\n",
    "        \"span_idx\",\n",
    "        \"span_mask\",\n",
    "    ]\n",
    "    dynamic_axes = {\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"words_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"text_lengths\": {0: \"batch_size\", 1: \"value\"},\n",
    "        \"span_idx\": {0: \"batch_size\", 1: \"num_spans\", 2: \"idx\"},\n",
    "        \"span_mask\": {0: \"batch_size\", 1: \"num_spans\"},\n",
    "        \"logits\": {\n",
    "            0: \"batch_size\",\n",
    "            1: \"sequence_length\",\n",
    "            2: \"num_spans\",\n",
    "            3: \"num_classes\",\n",
    "        },\n",
    "    }\n",
    "print(\"Converting the model...\")\n",
    "\n",
    "torch.onnx.export(\n",
    "    export_wrapper,\n",
    "    all_inputs,\n",
    "    f=onnx_savepath,\n",
    "    input_names=input_names,\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes=dynamic_axes,\n",
    "    opset_version=14,\n",
    "    dynamo=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204e50d",
   "metadata": {},
   "source": [
    "### Copy Necessary Model Files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bda22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Copy config and tokenizer files to ONNX directory\n",
    "onnx_dir: Path = Path(\"gliner_small_v_2_p_1_local_onnx\")\n",
    "local_dir: Path = Path(\"gliner_small_v_2_p_1_local\")\n",
    "\n",
    "# Ensure ONNX directory exists\n",
    "onnx_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy config file\n",
    "shutil.copy(local_dir / \"gliner_config.json\", onnx_dir / \"gliner_config.json\")\n",
    "\n",
    "# Copy tokenizer files\n",
    "tokenizer_files: list[str] = [\n",
    "    \"added_tokens.json\",\n",
    "    \"special_tokens_map.json\",\n",
    "    \"spm.model\",\n",
    "    \"tokenizer_config.json\",\n",
    "    \"tokenizer.json\",\n",
    "]\n",
    "for file in tokenizer_files:\n",
    "    src: Path = local_dir / file\n",
    "    dst: Path = onnx_dir / file\n",
    "    if src.exists():\n",
    "        shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad17365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted entities: [{'start': 0, 'end': 4, 'text': 'ONNX', 'label': 'format', 'score': 0.9161803722381592}, {'start': 73, 'end': 82, 'text': 'AI models', 'label': 'model', 'score': 0.768403172492981}]\n"
     ]
    }
   ],
   "source": [
    "# Test the ONNX model\n",
    "text = (\n",
    "    \"ONNX is an open-source format designed to enable the interoperability of AI models across various frameworks and tools.\"\n",
    ")\n",
    "labels = [\"format\", \"model\", \"tool\", \"cat\"]\n",
    "\n",
    "entities = model.predict_entities(text, labels)\n",
    "print(\"Predicted entities:\", entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14645a66",
   "metadata": {},
   "source": [
    "## Quantize The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4426be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
      "WARNING:root:Inference failed or unsupported type to quantize for tensor '/backend_model/NonZero_output_0', type is tensor_type {\n",
      "  elem_type: 7\n",
      "  shape {\n",
      "    dim {\n",
      "      dim_value: 2\n",
      "    }\n",
      "    dim {\n",
      "      dim_param: \"unk__404\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      ".\n",
      "WARNING:root:Inference failed or unsupported type to quantize for tensor '/backend_model/NonZero_1_output_0', type is tensor_type {\n",
      "  elem_type: 7\n",
      "  shape {\n",
      "    dim {\n",
      "      dim_value: 2\n",
      "    }\n",
      "    dim {\n",
      "      dim_param: \"unk__405\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      ".\n",
      "WARNING:root:Inference failed or unsupported type to quantize for tensor '/backend_model/NonZero_2_output_0', type is tensor_type {\n",
      "  elem_type: 7\n",
      "  shape {\n",
      "    dim {\n",
      "      dim_value: 2\n",
      "    }\n",
      "    dim {\n",
      "      dim_param: \"unk__419\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# quantize model\n",
    "from onnxruntime.quantization import QuantType, quantize_dynamic\n",
    "\n",
    "quantized_save_path = Path(\"gliner_small_v_2_p_1_local_onnx\") / \"model_quantized.onnx\"\n",
    "# Quantize the ONNX model\n",
    "print(\"Quantizing the model...\")\n",
    "quantize_dynamic(\n",
    "    onnx_savepath,  # Input model\n",
    "    quantized_save_path,  # Output model\n",
    "    weight_type=QuantType.QUInt8,  # Quantize weights to 8-bit integers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d498b92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in /Users/mac/Desktop/Projects/gliner_test/gliner_small_v_2_p_1_local_onnx\n",
      "WARNING:huggingface_hub.hub_mixin:config.json not found in /Users/mac/Desktop/Projects/gliner_test/gliner_small_v_2_p_1_local_onnx\n"
     ]
    }
   ],
   "source": [
    "# load quantized model\n",
    "model = GLiNER.from_pretrained(\n",
    "    \"./gliner_small_v_2_p_1_local_onnx/\",\n",
    "    load_onnx_model=True,\n",
    "    load_tokenizer=True,\n",
    "    onnx_model_file=\"model_quantized.onnx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b7784e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adebayo Davies => person (score: 0.8450)\n",
      "Emeka Jonathan => person (score: 0.7873)\n"
     ]
    }
   ],
   "source": [
    "text: str = \"\"\"\n",
    "Transfer from Adebayo Davies to Emeka Jonathan via Opay\n",
    "\"\"\"\n",
    "\n",
    "labels = [\"person\", \"bank\", \"location\"]\n",
    "\n",
    "entities = model.predict_entities(text, labels, threshold=0.4)\n",
    "\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"], f\"(score: {entity['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693155f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855c58d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d58b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795f1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gliner_test (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
